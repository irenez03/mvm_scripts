{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Step 0: Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "from functools import lru_cache\n",
        "from typing import Dict, Set, List, Iterator, Optional, Tuple\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Step 1: Import Showcase Line-UP as CSV**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "pathfile = \"/Users/iz132/Desktop/f25/mvm_script/F25_LineUp - Sheet1.csv\"\n",
        "df = pd.read_csv(pathfile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Step 2: Clean Data from CSV as Needed**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to normalize names\n",
        "def normalize_name(name):\n",
        "    \"\"\"\n",
        "    Normalize a name to lowercase with underscores.\n",
        "    Handles common variations and inconsistencies.\n",
        "    \"\"\"\n",
        "    if pd.isna(name) or name == '':\n",
        "        return name\n",
        "    \n",
        "    # Strip whitespace first\n",
        "    name = str(name).strip()\n",
        "    \n",
        "    # Convert to lowercase\n",
        "    name = name.lower()\n",
        "    \n",
        "    # Remove periods\n",
        "    name = name.replace('.', '')\n",
        "    \n",
        "    # Replace spaces with underscores\n",
        "    name = name.replace(' ', '_')\n",
        "    \n",
        "    return name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert all cell values to lowercase\n",
        "df = df.apply(lambda col: col.str.lower() if col.dtype == \"object\" else col)\n",
        "\n",
        "# Strip whitespace from all cell values\n",
        "df = df.apply(lambda col: col.str.strip() if col.dtype == \"object\" else col)\n",
        "\n",
        "# Apply the normalize_name function to all cell values\n",
        "df = df.apply(lambda col: col.apply(normalize_name) if col.dtype == \"object\" else col)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Step 3: Create mappings from CSV to Dictionary (Preprocess)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "teams_to_members = {\n",
            "    \"go\": {\"angie\", \"justin\", \"leo_z\", \"luke\", \"meso\", \"sophia_z\", \"timothy\"},\n",
            "    \"nxde\": {\"angela\", \"aslan\", \"eni\", \"meso\", \"sherla\"},\n",
            "    \"loco\": {\"adell\", \"aslan\", \"ava\", \"elena\", \"sua\"},\n",
            "    \"guilty\": {\"joey\", \"sophia_d\", \"sophia_z\", \"vivian\", \"wei_lun\"},\n",
            "    \"bad_villain\": {\"andy\", \"eni\", \"haeun\", \"hairuo\", \"mandy\", \"meso\", \"vivian\"},\n",
            "    \"last_festival\": {\"andy\", \"brandon\", \"irene\", \"max\", \"roxanne\", \"sean\"},\n",
            "    \"hot\": {\"ava\", \"neha\", \"roxanne\", \"sarea\", \"sua\"},\n",
            "    \"famous\": {\"elena\", \"hairuo\", \"joey\", \"kaiki\", \"leo_shen\"},\n",
            "    \"dirty_work\": {\"aslan\", \"hairuo\", \"kaiki\", \"sabrina\"},\n",
            "    \"drip\": {\"irene\", \"irving\", \"phuong\", \"talia\", \"yuna\"},\n",
            "    \"plot_twist\": {\"andrew_liu\", \"brandon\", \"leo_shen\", \"lisa\", \"sophia_z\", \"timothy\"},\n",
            "    \"xoxz\": {\"andrew_lee\", \"aslan\", \"chunzhen\", \"irene\", \"sarea\", \"talia\"},\n",
            "    \"siren\": {\"adell\", \"chi\", \"kaiki\", \"kaylee\", \"phuong\", \"sean\", \"talia\"},\n",
            "    \"grabriela\": {\"angela\", \"haeun\", \"michael\", \"sherla\", \"vivian\"},\n",
            "    \"jellyous\": {\"kaylee\", \"lisa\", \"max\", \"michael\", \"sabrina\"},\n",
            "    \"dope\": {\"andrew_lee\", \"andy\", \"joey\", \"kaylee\", \"leo_shen\", \"max\", \"sophia_d\"},\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Auto-generate teams_to_members dictionary from cleaned DataFrame\n",
        "\n",
        "teams_to_members = {}\n",
        "\n",
        "for col in df.columns:\n",
        "    members = df[col].dropna()\n",
        "    members = members[members != '']\n",
        "    teams_to_members[col] = set(members.unique())\n",
        "\n",
        "# Print in the same format as your sample_teams_data\n",
        "print(\"teams_to_members = {\")\n",
        "for team, members in teams_to_members.items():\n",
        "    members_str = ', '.join(f'\"{m}\"' for m in sorted(members))\n",
        "    print(f'    \"{team}\": {{{members_str}}},')\n",
        "print(\"}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Step 4: Run Script to Find Optimal Order**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SetlistSolver:\n",
        "    \"\"\"\n",
        "    Finds and counts valid sequences of teams (setlists) where no two\n",
        "    adjacent teams share a member (Hamiltonian paths in a compatibility graph).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, teams_to_members: Dict[str, Set[str]]):\n",
        "        if not teams_to_members:\n",
        "            raise ValueError(\"Input `teams_to_members` cannot be empty.\")\n",
        "\n",
        "        # Light sanitization: strip whitespace around member names\n",
        "        self.teams_to_members: Dict[str, Set[str]] = {\n",
        "            team: {str(m).strip() for m in members}\n",
        "            for team, members in teams_to_members.items()\n",
        "        }\n",
        "\n",
        "        self.teams: List[str] = list(self.teams_to_members.keys())\n",
        "        self.team_count: int = len(self.teams)\n",
        "        self.team_to_idx: Dict[str, int] = {team: i for i, team in enumerate(self.teams)}\n",
        "        self.adjacency_masks: List[int] = self._build_compatibility_graph()\n",
        "\n",
        "    def _build_compatibility_graph(self) -> List[int]:\n",
        "        \"\"\"Bitmask adjacency: adj[i] has bit j set iff team i is compatible with j.\"\"\"\n",
        "        adj = [0] * self.team_count\n",
        "        for i, team_i in enumerate(self.teams):\n",
        "            members_i = self.teams_to_members[team_i]\n",
        "            mask = 0\n",
        "            for j, team_j in enumerate(self.teams):\n",
        "                if i == j:\n",
        "                    continue\n",
        "                if self.teams_to_members[team_j].isdisjoint(members_i):\n",
        "                    mask |= (1 << j)\n",
        "            adj[i] = mask\n",
        "        return adj\n",
        "\n",
        "    # ---------- Generate valid setlists (optional start/end constraints) ----------\n",
        "\n",
        "    def generate_valid_setlists(\n",
        "        self,\n",
        "        limit: Optional[int] = None,\n",
        "        start_team: Optional[str] = None,\n",
        "        end_team: Optional[str] = None,\n",
        "        debug: bool = False,\n",
        "    ) -> Iterator[List[str]]:\n",
        "        \"\"\"\n",
        "        Backtracking + heuristics. Before yielding, we STRICTLY validate that\n",
        "        each adjacent pair shares no members (guarding against data issues).\n",
        "        \"\"\"\n",
        "        if start_team and start_team not in self.team_to_idx:\n",
        "            raise ValueError(f\"Start team '{start_team}' not found.\")\n",
        "        if end_team and end_team not in self.team_to_idx:\n",
        "            raise ValueError(f\"End team '{end_team}' not found.\")\n",
        "\n",
        "        # Heuristic: try nodes with fewer neighbors first (tighter first)\n",
        "        ranked_indices = sorted(\n",
        "            range(self.team_count),\n",
        "            key=lambda i: bin(self.adjacency_masks[i]).count(\"1\")\n",
        "        )\n",
        "        idx_to_rank = {orig: r for r, orig in enumerate(ranked_indices)}\n",
        "\n",
        "        # Reindex adjacency + names according to ranking\n",
        "        adj_r = [0] * self.team_count\n",
        "        teams_r = [self.teams[i] for i in ranked_indices]\n",
        "        for i in range(self.team_count):\n",
        "            original_mask = self.adjacency_masks[i]\n",
        "            m = 0\n",
        "            for j in range(self.team_count):\n",
        "                if (original_mask >> j) & 1:\n",
        "                    m |= (1 << idx_to_rank[j])\n",
        "            adj_r[idx_to_rank[i]] = m\n",
        "\n",
        "        start_node_r = idx_to_rank[self.team_to_idx[start_team]] if start_team else None\n",
        "        end_node_r   = idx_to_rank[self.team_to_idx[end_team]]   if end_team   else None\n",
        "\n",
        "        produced = 0\n",
        "        for path_indices in self._backtrack_with_end(adj_r, start_node_r, end_node_r):\n",
        "            if limit is not None and produced >= limit:\n",
        "                return\n",
        "\n",
        "            # Convert to team names\n",
        "            seq = [teams_r[i] for i in path_indices]\n",
        "\n",
        "            # STRICT VALIDATION: verify every adjacent pair has disjoint members\n",
        "            ok, conflict = self._sequence_is_valid(seq)\n",
        "            if not ok:\n",
        "                if debug:\n",
        "                    a, b, overlap = conflict\n",
        "                    print(f\"[skip invalid] {a} -> {b} shares members: {sorted(overlap)}\")\n",
        "                continue\n",
        "\n",
        "            yield seq\n",
        "            produced += 1\n",
        "\n",
        "    def _backtrack_with_end(\n",
        "        self,\n",
        "        adj_r: List[int],\n",
        "        start_node_r: Optional[int],\n",
        "        end_node_r: Optional[int],\n",
        "    ) -> Iterator[List[int]]:\n",
        "        \"\"\"\n",
        "        Enforce fixed end by forbidding `end_node_r` until last slot and\n",
        "        forcing it at the final step (if reachable).\n",
        "        \"\"\"\n",
        "        n = self.team_count\n",
        "        path: List[int] = []\n",
        "        used_mask = 0\n",
        "\n",
        "        def solve():\n",
        "            nonlocal used_mask\n",
        "            L = len(path)\n",
        "            if L == n:\n",
        "                if end_node_r is None or path[-1] == end_node_r:\n",
        "                    yield path.copy()\n",
        "                return\n",
        "\n",
        "            if L == 0:\n",
        "                candidates = [start_node_r] if start_node_r is not None else list(range(n))\n",
        "            else:\n",
        "                last = path[-1]\n",
        "                allowed = adj_r[last] & ~used_mask\n",
        "\n",
        "                if end_node_r is not None and L < n - 1:\n",
        "                    allowed &= ~(1 << end_node_r)\n",
        "\n",
        "                if end_node_r is not None and L == n - 1:\n",
        "                    if (allowed >> end_node_r) & 1:\n",
        "                        allowed = (1 << end_node_r)\n",
        "                    else:\n",
        "                        return  # cannot reach required end\n",
        "\n",
        "                candidates = []\n",
        "                x = allowed\n",
        "                while x:\n",
        "                    lsb = x & -x\n",
        "                    candidates.append(lsb.bit_length() - 1)\n",
        "                    x ^= lsb\n",
        "\n",
        "                # heuristic: fewest future options first\n",
        "                candidates.sort(key=lambda c: bin(adj_r[c] & ~used_mask).count(\"1\"))\n",
        "\n",
        "            for c in candidates:\n",
        "                if (used_mask >> c) & 1:\n",
        "                    continue\n",
        "                path.append(c)\n",
        "                used_mask |= (1 << c)\n",
        "                yield from solve()\n",
        "                used_mask &= ~(1 << c)\n",
        "                path.pop()\n",
        "\n",
        "        yield from solve()\n",
        "\n",
        "    # ---------- Validation & Debug helpers ----------\n",
        "\n",
        "    def _sequence_is_valid(self, seq: List[str]) -> Tuple[bool, Optional[Tuple[str, str, Set[str]]]]:\n",
        "        \"\"\"Return (True, None) if valid; else (False, (teamA, teamB, overlapping_members)).\"\"\"\n",
        "        for a, b in zip(seq, seq[1:]):\n",
        "            overlap = self.teams_to_members[a] & self.teams_to_members[b]\n",
        "            if overlap:\n",
        "                return False, (a, b, overlap)\n",
        "        return True, None\n",
        "\n",
        "    def explain_pair(self, team_a: str, team_b: str) -> None:\n",
        "        \"\"\"Print the intersection (if any) for a quick manual check.\"\"\"\n",
        "        inter = self.teams_to_members[team_a] & self.teams_to_members[team_b]\n",
        "        if inter:\n",
        "            print(f\"{team_a} and {team_b} share: {sorted(inter)}\")\n",
        "        else:\n",
        "            print(f\"{team_a} and {team_b} are compatible (no shared members).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Working with 16 teams.\n"
          ]
        }
      ],
      "source": [
        "# Initialize the solver\n",
        "solver = SetlistSolver(teams_to_members)\n",
        "\n",
        "# Quick sanity check (uncomment to use):\n",
        "# solver.explain_pair(\"plot_twist\", \"famous\")\n",
        "\n",
        "print(f\"Working with {solver.team_count} teams.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Find Setlists with Constraints\n",
        "\n",
        "Find setlists with fixed start, end, and multiple fixed middle team positions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define all of your constraints here\n",
        "start = \"go\"\n",
        "end = \"dope\"\n",
        "\n",
        "# First positional constraint\n",
        "target_team_1 = \"xoxz\"\n",
        "target_position_index_1 = 8\n",
        "\n",
        "# Second positional constraint\n",
        "target_team_2 = \"bad_villain\"\n",
        "target_position_index_2 = 7\n",
        "\n",
        "# Third positional constraint\n",
        "target_team_3 = \"siren\"\n",
        "target_position_index_3 = 11\n",
        "\n",
        "# Fourth positional constraint\n",
        "target_team_4 = \"drip\"\n",
        "target_position_index_4 = 14\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Finding setlists starting with 'go', ending with 'dope', with 'xoxz' in position 9, 'bad_villain' in position 8, 'siren' in position 12, and 'drip' in position 15 ---\n",
            "1: ['go', 'last_festival', 'famous', 'nxde', 'jellyous', 'loco', 'plot_twist', 'bad_villain', 'xoxz', 'guilty', 'hot', 'siren', 'grabriela', 'dirty_work', 'drip', 'dope']\n",
            "2: ['go', 'last_festival', 'famous', 'nxde', 'jellyous', 'loco', 'plot_twist', 'bad_villain', 'xoxz', 'grabriela', 'hot', 'siren', 'guilty', 'dirty_work', 'drip', 'dope']\n",
            "3: ['go', 'last_festival', 'famous', 'nxde', 'jellyous', 'guilty', 'loco', 'bad_villain', 'xoxz', 'plot_twist', 'grabriela', 'siren', 'hot', 'dirty_work', 'drip', 'dope']\n",
            "4: ['go', 'last_festival', 'famous', 'nxde', 'jellyous', 'guilty', 'loco', 'bad_villain', 'xoxz', 'plot_twist', 'hot', 'siren', 'grabriela', 'dirty_work', 'drip', 'dope']\n",
            "5: ['go', 'last_festival', 'famous', 'nxde', 'jellyous', 'guilty', 'loco', 'bad_villain', 'xoxz', 'grabriela', 'plot_twist', 'siren', 'hot', 'dirty_work', 'drip', 'dope']\n",
            "6: ['go', 'last_festival', 'famous', 'nxde', 'jellyous', 'guilty', 'loco', 'bad_villain', 'xoxz', 'grabriela', 'hot', 'siren', 'plot_twist', 'dirty_work', 'drip', 'dope']\n",
            "7: ['go', 'last_festival', 'famous', 'nxde', 'guilty', 'dirty_work', 'plot_twist', 'bad_villain', 'xoxz', 'jellyous', 'hot', 'siren', 'grabriela', 'loco', 'drip', 'dope']\n",
            "8: ['go', 'last_festival', 'famous', 'nxde', 'guilty', 'jellyous', 'loco', 'bad_villain', 'xoxz', 'plot_twist', 'grabriela', 'siren', 'hot', 'dirty_work', 'drip', 'dope']\n",
            "9: ['go', 'last_festival', 'famous', 'nxde', 'guilty', 'jellyous', 'loco', 'bad_villain', 'xoxz', 'plot_twist', 'hot', 'siren', 'grabriela', 'dirty_work', 'drip', 'dope']\n",
            "10: ['go', 'last_festival', 'famous', 'nxde', 'guilty', 'jellyous', 'loco', 'bad_villain', 'xoxz', 'grabriela', 'plot_twist', 'siren', 'hot', 'dirty_work', 'drip', 'dope']\n"
          ]
        }
      ],
      "source": [
        "# Run the search\n",
        "try:\n",
        "    print(\n",
        "        f\"\\n--- Finding setlists starting with '{start}', ending with '{end}', \"\n",
        "        f\"with '{target_team_1}' in position {target_position_index_1 + 1}, \"\n",
        "        f\"'{target_team_2}' in position {target_position_index_2 + 1}, \"\n",
        "        f\"'{target_team_3}' in position {target_position_index_3 + 1}, \"\n",
        "        f\"and '{target_team_4}' in position {target_position_index_4 + 1} ---\"\n",
        "    )\n",
        "\n",
        "    found_count = 0\n",
        "    limit = 10  # Find up to 10 examples\n",
        "\n",
        "    # Call the generator with the start and end teams locked\n",
        "    generator = solver.generate_valid_setlists(\n",
        "        start_team=start,\n",
        "        end_team=end\n",
        "    )\n",
        "\n",
        "    # Loop through the results and apply all positional checks\n",
        "    for setlist in generator:\n",
        "        # Check all four positional constraints\n",
        "        if (\n",
        "            len(setlist) > target_position_index_1\n",
        "            and setlist[target_position_index_1] == target_team_1\n",
        "            and len(setlist) > target_position_index_2\n",
        "            and setlist[target_position_index_2] == target_team_2\n",
        "            and len(setlist) > target_position_index_3\n",
        "            and setlist[target_position_index_3] == target_team_3\n",
        "            and len(setlist) > target_position_index_4\n",
        "            and setlist[target_position_index_4] == target_team_4\n",
        "        ):\n",
        "            found_count += 1\n",
        "            print(f\"{found_count}: {setlist}\")\n",
        "\n",
        "        if found_count >= limit:\n",
        "            break\n",
        "\n",
        "    if found_count == 0:\n",
        "        print(\"No valid setlists found that satisfy all specified conditions.\")\n",
        "\n",
        "except ValueError as e:\n",
        "    print(f\"Error: {e}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.13 (venv)",
      "language": "python",
      "name": "py313"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
